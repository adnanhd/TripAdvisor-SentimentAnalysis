{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from re import search\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47178c",
   "metadata": {},
   "source": [
    "YardÄ±mcÄ± fonksiyonlar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70fb0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_remove_url(tweet: str):\n",
    "    tweet = \" \".join([w for w in tweet.split() if not w.startswith(\"@\")])\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", tweet).split())\n",
    "\n",
    "\n",
    "def remove_url(tweet: str):\n",
    "    words = [w for w in tweet.split() if not (search(\"http\", w) or search(\"www\", w) or search('@', w))]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c52267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pos_filter(tweet_pos: list):\n",
    "    filtered_tweet = list()\n",
    "    pos_tags = (\"J\", \"V\", \"R\", \"N\")\n",
    "    for i in tweet_pos:\n",
    "        if i[1].startswith(pos_tags):\n",
    "            filtered_tweet.append((i[0], i[1]))\n",
    "    return filtered_tweet\n",
    "\n",
    "\n",
    "def pos_converter(tag: str):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bea75",
   "metadata": {},
   "source": [
    "Eski Pre-Process fonksiyonu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce8a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet: str):\n",
    "    wordss = word_tokenize(remove_url(tweet))\n",
    "\n",
    "    new_words = pos_filter(nltk.pos_tag(wordss))\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stop_words = set([\"'\" + w for w in stop_words] + list(stop_words))\n",
    "\n",
    "    no_stops = [word for word in new_words if (word[0].lower() not in stop_words)]\n",
    "\n",
    "    lmtz = WordNetLemmatizer()\n",
    "    pos_list = pos_filter(no_stops)\n",
    "    lemmas = [lmtz.lemmatize(tup[0].lower(), pos=pos_converter(tup[1])) for tup in pos_list]\n",
    "    new_tweet = \" \".join(lemmas)\n",
    "\n",
    "    return sec_remove_url(new_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45913293",
   "metadata": {},
   "source": [
    "Yeni Pre-Process fonksiyonu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655bcc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    # remove stock market signs like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = []\n",
    "    pos_tags = nltk.pos_tag(tweet_tokens)\n",
    "    pos_tags = pos_filter(pos_tags)\n",
    "    for word, tag in pos_tags:\n",
    "        if word not in stopwords_english and word not in string.punctuation:\n",
    "            stem_word = lemmatizer.lemmatize(word, pos=pos_converter(tag))  # lemmatize word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64986590",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"@RealAmVoice @TudorDixon ðŸ‡ºðŸ‡¸ America went from :D having one of the worldâ€™s worst Covid rates to having one of the best. ðŸ‡ºðŸ‡¸  We are now once again topping the world list of reported Covid cases.  Sabotaging the CDCâ€™s efforts to contain this virus is UN-AMERICAN, UNPATRIOTIC and downright INHUMAN. https://t.co/DdEWnF0MXj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f1a4941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "america go world bad covid rate best top world list report covid case sabotage cdc effort contain virus unamerican unpatriotic downright inhuman\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(tweet))\n",
    "print(preprocess(\"ðŸ‡ºðŸ‡¸\"))\n",
    "print(preprocess(\":D . * / ' , :/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e481716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‡º ðŸ‡¸ america go :D world â€™ bad covid rate best ðŸ‡º top world list report covid case sabotage cdc â€™ effort contain virus un-american unpatriotic downright inhuman\n",
      "ðŸ‡º ðŸ‡¸\n",
      ":D :/\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(process_tweet(tweet)))\n",
    "print(\" \".join(process_tweet(\"ðŸ‡ºðŸ‡¸\")))\n",
    "print(\" \".join(process_tweet(\":D . * / ' , :/\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
